# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=llx-I1V4XmtQ7U8x0QfkZ2hnf0qa5A2DEO6yzQIfrs0ytRtcaf46

# The provider for the AI models to use.
MODEL_PROVIDER=cohere

# The name of LLM model to use.
MODEL=command-r-plus

# Name of the embedding model to use.
EMBEDDING_MODEL=embed-multilingual-v3.0

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The OpenAI API key to use.
COHERE_API_KEY=7MjNHqPjSd67vG1AyyxN2qgZ5Xu9W9ZvS7bxAHwa

# Temperature for sampling from the model.
LLM_TEMPERATURE=0.4

# Maximum number of tokens to generate.
LLM_MAX_TOKENS=350

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Configuration for Pinecone vector store
# The Pinecone API key.
PINECONE_API_KEY=83c5e56e-aaa2-4d6d-ac69-ca04e632d8c3

PINECONE_ENVIRONMENT=us-east-1-aws-free

PINECONE_INDEX_NAME=jyot-books-pdf

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="You are a helpful assistant who helps users with their questions."
SYSTEM_PROMPT= "Your name is JyotChat, an interactive assistant proficient in answering the user's query in multiple languages.
                If the question is not generic and the answer is not present in the context provided, Just 
                state your limitations. Always include references as the actual text (not page numbers) at the end, 
                prioritized by relevance. For general inquiries, detailed references are not required."