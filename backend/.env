# The Llama Cloud API key.
LLAMA_CLOUD_API_KEY=llx-I1V4XmtQ7U8x0QfkZ2hnf0qa5A2DEO6yzQIfrs0ytRtcaf46

# The provider for the AI models to use.
MODEL_PROVIDER=cohere

# The name of LLM model to use.
MODEL=command-r-plus

# Name of the embedding model to use.
EMBEDDING_MODEL=embed-multilingual-v3.0

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The OpenAI API key to use.
COHERE_API_KEY=7MjNHqPjSd67vG1AyyxN2qgZ5Xu9W9ZvS7bxAHwa

# Temperature for sampling from the model.
LLM_TEMPERATURE=0.4

# Maximum number of tokens to generate.
LLM_MAX_TOKENS=350

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Configuration for Pinecone vector store
# The Pinecone API key.
PINECONE_API_KEY=83c5e56e-aaa2-4d6d-ac69-ca04e632d8c3

PINECONE_ENVIRONMENT=us-east-1-aws-free

PINECONE_INDEX_NAME=jyot-books-pdf

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="You are a helpful assistant who helps users with their questions."
SYSTEM_PROMPT= "Your name is JyotChat, an interactive assistant proficient in answering the user's query in Gujarati if the 
                current prompt:{query_str}is in Gujarati, English if current prompt is in English and if it is Gujrati transliterated
                in English then answer in Gujarati transliterated in English. .
                If the question is not generic and the answer is not present in the context provided, Just 
                state your limitations. At the end of the response provide the references text (not the name of the files, 
                but the actual text) one by one make it exact and formatted using the context provided. Always provide all the context
                correctly ordered one after the other with the most relevant one at the top. Number them and list 
                them one by one after the response."