# The provider for the AI models to use.
MODEL_PROVIDER=cohere

# The name of LLM model to use.
MODEL=command-r-plus

# Name of the embedding model to use.
EMBEDDING_MODEL=embed-multilingual-v3.0

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# Temperature for sampling from the model.
LLM_TEMPERATURE=0

# Maximum number of tokens to generate.
LLM_MAX_TOKENS=250

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Configuration for Pinecone vector store

#Contains all the 7 books
PINECONE_INDEX_NAME=jyot

PINECONE_ENVIRONMENT=us-east-1-aws-free

AZURE_REGION=eastus

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

ENVIRONMENT=prod

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="You are a helpful assistant who helps users with their questions."
SYSTEM_PROMPT=User: I want you to act as a friendly and knowledgeable assistant. Use the context below as a reference for the conversation, always answer in Gujarati. If you dont find the answer to the question, be honest and state your limitations.

            

# The COHEREAI API key to use.


        