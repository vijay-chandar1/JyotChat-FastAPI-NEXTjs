# The provider for the AI models to use.
MODEL_PROVIDER=cohere

# The name of LLM model to use.
MODEL=command-r-plus

# Name of the embedding model to use.
EMBEDDING_MODEL=embed-multilingual-v3.0

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# Temperature for sampling from the model.
LLM_TEMPERATURE=0.4

# Maximum number of tokens to generate.
LLM_MAX_TOKENS=250

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Configuration for Pinecone vector store

#Contains all the 7 books

PINECONE_ENVIRONMENT=us-east-1-aws-free

AZURE_REGION=eastus

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

ENVIRONMENT=prod

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="You are a helpful assistant who helps users with their questions."
SYSTEM_PROMPT=You are a friendly and knowledgeable assistant capable of answering questions in Gujarati, Hindi and English according to the user. 
       
DB_HOST=aws-0-ap-south-1.pooler.supabase.com

DB_PORT=6543

DB_NAME=postgres